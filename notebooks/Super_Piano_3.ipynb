{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9opKSK2RSDRg"
      },
      "source": [
        "# Super Piano 3: Google Music Transformer\n",
        "## Generating Music with Long-Term structure\n",
        "### Based on 2019 ICLR paper by Cheng-Zhi Anna Huang, Google Brain and Damon Gwinn's code/repo https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "Huge thanks go out to the following people who contributed the code/repos used in this colab. Additional contributors are listed in the code as well.\n",
        "\n",
        "1) Kevin-Yang https://github.com/jason9693/midi-neural-processor\n",
        "\n",
        "2) gudgud96 for fixing Kevin's MIDI Encoder properly https://github.com/gudgud96\n",
        "\n",
        "2) jinyi12, Zac Koh, Akamight, Zhang https://github.com/COMP6248-Reproducability-Challenge/music-transformer-comp6248\n",
        "\n",
        "Thank you so much for your hard work and for sharing it with the world :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified slightly by Maya Shen for Group 4's Project 3 for 10-615: Art and ML at CMU"
      ],
      "metadata": {
        "id": "vfFkZr4fU_pR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hD19W0hSCP"
      },
      "source": [
        "###Setup Environment and Dependencies. Check GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ror_UJUp7wlO"
      },
      "outputs": [],
      "source": [
        "#@title Check if GPU (driver) is availiable (you do not want to run this on CPU, trust me)\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "paYvoZHihtux"
      },
      "outputs": [],
      "source": [
        "#@title Clone/Install all dependencies\n",
        "!git clone https://github.com/asigalov61/midi-neural-processor\n",
        "!git clone https://github.com/asigalov61/MusicTransformer-Pytorch\n",
        "!pip install tqdm\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install librosa\n",
        "!pip install scipy\n",
        "!pip install pillow\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install mir_eval\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VM71tUPVfffi"
      },
      "outputs": [],
      "source": [
        "#@title Import all needed modules\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "# For plotting\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "#%matplotlib inline\n",
        "#matplotlib.get_backend()\n",
        "import mir_eval.display\n",
        "import librosa\n",
        "import librosa.display\n",
        "# For rendering output audio\n",
        "import pretty_midi\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34spqHYPJtTJ"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Pre-trained models download (2 models trained for 100 epochs to 1.968 FLoss and 0.420 acc)\n",
        "!mkdir /content/MusicTransformer-Pytorch/rpr\n",
        "!mkdir /content/MusicTransformer-Pytorch/rpr/results\n",
        "%cd /content/MusicTransformer-Pytorch/rpr/results\n",
        "!wget 'https://superpiano.s3-us-west-1.amazonaws.com/SuperPiano3models.zip'\n",
        "!unzip SuperPiano3models.zip\n",
        "%cd /content/MusicTransformer-Pytorch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kE-VhygOPuG"
      },
      "source": [
        "#Please note that you MUST DOWNLOAD AND PROCESS ONE OF THE DATASETS TO TRAIN OR TO USE PRE-TRAINED MODEL as it primes the model from DATASET files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gd-O5LZyJGD"
      },
      "source": [
        "#Option 1: MAESTRO DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0bGqw8o6oxUY"
      },
      "outputs": [],
      "source": [
        "#@title Download Google Magenta MAESTRO v.2.0.0 Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/MusicTransformer-Pytorch/dataset/\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip maestro-v2.0.0-midi.zip\n",
        "%cd /content/MusicTransformer-Pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXiyUuuonMqM"
      },
      "outputs": [],
      "source": [
        "#@title Prepare directory structure and MIDI processor\n",
        "%cd /content/\n",
        "!mv midi-neural-processor midi_processor\n",
        "%cd /content/MusicTransformer-Pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vN-bpkEGxSMY"
      },
      "outputs": [],
      "source": [
        "#@title Process MAESTRO MIDI DataSet\n",
        "!python3 preprocess_midi.py '/content/MusicTransformer-Pytorch/dataset/maestro-v2.0.0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKz4SKoeXYWc"
      },
      "source": [
        "#Option 2: Your own Custom MIDI DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27zmkAM9vEGX"
      },
      "outputs": [],
      "source": [
        "#@title Create directory structure for the DataSet and prep MIDI processor\n",
        "\n",
        "!mkdir '/content/MusicTransformer-Pytorch/dataset/e_piano/'\n",
        "!mkdir '/content/MusicTransformer-Pytorch/dataset/e_piano/train'\n",
        "!mkdir '/content/MusicTransformer-Pytorch/dataset/e_piano/test'\n",
        "!mkdir '/content/MusicTransformer-Pytorch/dataset/e_piano/val'\n",
        "!mkdir '/content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis'\n",
        "\n",
        "%cd /content/\n",
        "!mv midi-neural-processor midi_processor\n",
        "%cd /content/MusicTransformer-Pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete old custom MIDI dataset if necessary\n",
        "\n",
        "!rm -f /content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis/*"
      ],
      "metadata": {
        "id": "Ln_M15bKTxNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUXaozztvGU2"
      },
      "outputs": [],
      "source": [
        "#@title Upload your custom MIDI DataSet to created \"dataset/e_piano/custom_midis\" folder through this cell or manually through any other means. You can also use ready-to-use DataSets below\n",
        "from google.colab import files\n",
        "%cd '/content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis'\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uDsmK-vkwOgl"
      },
      "outputs": [],
      "source": [
        "#@title (The Best Choice/Works best stand-alone) Super Piano 2 Original 2500 MIDIs of Piano Music\n",
        "%cd /content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis\n",
        "!wget 'https://github.com/asigalov61/SuperPiano/raw/master/Super_Piano_2_MIDI_DataSet_CC_BY_NC_SA.zip'\n",
        "!unzip -j 'Super_Piano_2_MIDI_DataSet_CC_BY_NC_SA.zip'\n",
        "!rm Super_Piano_2_MIDI_DataSet_CC_BY_NC_SA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "feA03YKvwgaV"
      },
      "outputs": [],
      "source": [
        "#@title (Second Best Choice/Works best stand-alone) Alex Piano Only Original 450 MIDIs \n",
        "%cd /content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'\n",
        "!rm AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-jAV_Qv5Fn_"
      },
      "source": [
        "For now, we are going to split the dataset by random into \"test\"/\"val\" dirs which is not ideal. So feel free to modify the code to your liking to achieve better training results with this implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ5c6d5lXemo"
      },
      "outputs": [],
      "source": [
        "#@title Process your custom MIDI DataSet :)\n",
        "%cd /content/MusicTransformer-Pytorch\n",
        "from processor import encode_midi\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "%cd '/content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis'\n",
        "\n",
        "custom_MIDI_DataSet_dir = '/content/MusicTransformer-Pytorch/dataset/e_piano/custom_midis'\n",
        "\n",
        "train_dir = '/content/MusicTransformer-Pytorch/dataset/e_piano/train' # split_type = 0\n",
        "test_dir = '/content/MusicTransformer-Pytorch/dataset/e_piano/test' # split_type = 1  \n",
        "val_dir = '/content/MusicTransformer-Pytorch/dataset/e_piano/val' # split_type = 2\n",
        "\n",
        "total_count = 0\n",
        "train_count = 0\n",
        "val_count   = 0\n",
        "test_count  = 0\n",
        "\n",
        "f_ext = '.pickle'\n",
        "fileList = os.listdir(custom_MIDI_DataSet_dir)\n",
        "for file in fileList:\n",
        "     # we gonna split by a random selection for now\n",
        "    \n",
        "    split = random.randint(1, 2)\n",
        "    if (split == 0):\n",
        "         o_file = os.path.join(train_dir, file+f_ext)\n",
        "         train_count += 1\n",
        "\n",
        "    elif (split == 2):\n",
        "         o_file0 = os.path.join(train_dir, file+f_ext)\n",
        "         train_count += 1\n",
        "         o_file = os.path.join(val_dir, file+f_ext)\n",
        "         val_count += 1\n",
        "\n",
        "    elif (split == 1):\n",
        "         o_file0 = os.path.join(train_dir, file+f_ext)\n",
        "         train_count += 1\n",
        "         o_file = os.path.join(test_dir, file+f_ext)\n",
        "         test_count += 1\n",
        "    try:\n",
        "      prepped = encode_midi(file)\n",
        "      o_stream = open(o_file0, \"wb\")\n",
        "      pickle.dump(prepped, o_stream)\n",
        "      o_stream.close()\n",
        "\n",
        "      prepped = encode_midi(file)\n",
        "      o_stream = open(o_file, \"wb\")\n",
        "      pickle.dump(prepped, o_stream)\n",
        "      o_stream.close()\n",
        "   \n",
        "      print(file)\n",
        "      print(o_file)\n",
        "      print('Coverted!')  \n",
        "    except KeyboardInterrupt: \n",
        "      raise   \n",
        "    except:\n",
        "      print('Bad file. Skipping...')\n",
        "\n",
        "print('Done')\n",
        "print(\"Num Train:\", train_count)\n",
        "print(\"Num Val:\", val_count)\n",
        "print(\"Num Test:\", test_count)\n",
        "print(\"Total Count:\", train_count)\n",
        "\n",
        "%cd /content/MusicTransformer-Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MusicTransformer-Pytorch\n",
        "from processor import encode_midi"
      ],
      "metadata": {
        "id": "90Ykr8gZcY3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwCQIziNwHxe"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete old training weights if necessary\n",
        "\n",
        "!rm -f /content/MusicTransformer-Pytorch/rpr/weights/*"
      ],
      "metadata": {
        "id": "IRRipa8tUDph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hwisXl2Iy_Xf"
      },
      "outputs": [],
      "source": [
        "#@title Activate Tensorboard Graphs/Stats to monitor/evaluate model perfomance during and after training runs\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/MusicTransformer-Pytorch/rpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbv_sJyLq5om"
      },
      "outputs": [],
      "source": [
        "#@title Start to Train the Model\n",
        "batch_size = 4 #@param {type:\"slider\", min:0, max:8, step:1}\n",
        "number_of_training_epochs = 100 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "maximum_output_MIDI_sequence = 2048 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "!python3 train.py -output_dir rpr --rpr -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence #-n_layers -num_heads -d_model -dim_feedforward"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download specific set of weights (epoch)\n",
        "from google.colab import files\n",
        "files.download('/content/MusicTransformer-Pytorch/rpr/weights/epoch_0025.pickle')"
      ],
      "metadata": {
        "id": "5FvUhVh4ckZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip all weights and save\n",
        "!zip -r '/content/MusicTransformer-Pytorch/rpr/weights/model3_weights.zip' '/content/MusicTransformer-Pytorch/rpr/weights'\n",
        "files.download('/content/MusicTransformer-Pytorch/rpr/weights/model3_weights.zip')"
      ],
      "metadata": {
        "id": "i6D7gGAhE-H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VLdhokSGUAu"
      },
      "outputs": [],
      "source": [
        "# Re-Start Training from a certain checkpoint and epoch\n",
        "batch_size = 4 # {type:\"slider\", min:0, max:8, step:1}\n",
        "number_of_training_epochs = 100 # {type:\"slider\", min:0, max:200, step:1}\n",
        "maximum_output_MIDI_sequence = 2048 # {type:\"slider\", min:0, max:8192, step:128}\n",
        "saved_checkpoint_full_path = \"/content/MusicTransformer-Pytorch/rpr/weights/epoch_0018.pickle\" # {type:\"string\"}\n",
        "continue_epoch_number =  18 # {type:\"integer\"}\n",
        "\n",
        "!python3 train.py -output_dir rpr --rpr -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence -continue_weights $saved_checkpoint_full_path -continue_epoch $continue_epoch_number #-n_layers -num_heads -d_model -dim_feedforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1D-o-E-TnI8"
      },
      "source": [
        "###Evaluate the resulted models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQLOmv7wrOos"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate Best Resulting Accuracy Model (best_acc_weights.pickle)\n",
        "!python3 evaluate.py -model_weights rpr/results/best_acc_weights.pickle --rpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7QftGOfTyx2"
      },
      "outputs": [],
      "source": [
        "#@title Evaluate Best Resulting Loss Model (best_loss_weights.pickle)\n",
        "!python3 evaluate.py -model_weights rpr/results/best_loss_weights.pickle --rpr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "results = pd.read_csv(\"/content/MusicTransformer-Pytorch/rpr/results/results.csv\")[:101]"
      ],
      "metadata": {
        "id": "aaPjvemcQcfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "L7V3QyTTSRJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results[['Avg Train loss']], label = \"Avg Train Loss\")\n",
        "plt.plot(results[['Avg Eval loss']], label = \"Avg Eval Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Super Piano 3 Ghibli Melody Generation: Loss by Training Epoch\")\n",
        "plt.savefig(\"/content/MusicTransformer-Pytorch/rpr/results/loss.jpg\", dpi  = 300)"
      ],
      "metadata": {
        "id": "-V1MklE-RBgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results[['Train Accuracy']], label = \"Train Accuracy\")\n",
        "plt.plot(results[['Eval accuracy']], label = \"Eval Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Super Piano 3 Ghibli Melody: Accuracy by Training Epoch\")\n",
        "plt.savefig(\"/content/MusicTransformer-Pytorch/rpr/results/acc.jpg\", dpi  = 300)"
      ],
      "metadata": {
        "id": "uTrYsXZVSNPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxHrTsFUdn-r"
      },
      "source": [
        "To have the model continue your custom MIDI enter the following into the custom_MIDI field below:\n",
        "\n",
        "-primer_file '/content/some_dir/some_seed_midi.mid'\n",
        "\n",
        "For example: -primer_file '/content/MusicTransformer-Pytorch/seed.mid'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJXWoBMWL3ph"
      },
      "source": [
        "# Generate and Explore the output :)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MIDI seed length for priming_sequence_length (for full seed)\n",
        "seed_MIDI = '/content/MusicTransformer-Pytorch/Seed1-Ascending-Am.mid' #@param {type:\"string\"}\n",
        "\n",
        "len(encode_midi(seed_MIDI)) - 1"
      ],
      "metadata": {
        "id": "kA_XHj7VSxqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czNulONr4tB6"
      },
      "outputs": [],
      "source": [
        "#@title Generate, Plot, Graph, Save, Download, and Render the resulting output\n",
        "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:1, max:2048, step:1}\n",
        "priming_sequence_length = 1024 #@param {type:\"slider\", min:1, max:2048, step:8}\n",
        "maximum_possible_output_sequence = 2048 #@param {type:\"slider\", min:0, max:2048, step:8}\n",
        "select_model = \"/content/MusicTransformer-Pytorch/rpr/results/best_acc_weights.pickle\" #@param [\"/content/MusicTransformer-Pytorch/rpr/results/best_acc_weights.pickle\", \"/content/MusicTransformer-Pytorch/rpr/results/best_loss_weights.pickle\"]\n",
        "seed_MIDI = \"-primer_file '/content/MusicTransformer-Pytorch/seed.mid'\" #@param {type:\"string\"}\n",
        "\n",
        "import processor\n",
        "from processor import encode_midi, decode_midi\n",
        "\n",
        "!python generate.py -output_dir output -model_weights=$select_model --rpr -target_seq_length=$number_of_tokens_to_generate -num_prime=$priming_sequence_length -max_sequence=$maximum_possible_output_sequence $seed_MIDI #\n",
        "\n",
        "print('Successfully exported the output to output folder. To primer.mid and rand.mid')\n",
        "\n",
        "# set the src and play\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio('/content/MusicTransformer-Pytorch/output/rand.mid', '/content/MusicTransformer-Pytorch/output/output.wav')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/MusicTransformer-Pytorch/output/rand.mid')\n",
        "files.download('/content/MusicTransformer-Pytorch/output/primer.mid')\n",
        "\n",
        "Audio('/content/MusicTransformer-Pytorch/output/output.wav')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/MusicTransformer-Pytorch/output/output.wav')"
      ],
      "metadata": {
        "id": "j71qq3C5gxq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG48uyKGzcTI"
      },
      "outputs": [],
      "source": [
        "#@title Plot and Graph the Output :)\n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "highest_displayed_pitch = 92 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "lowest_displayed_pitch = 24 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "piano_roll_color_map = \"Blues\"\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/MusicTransformer-Pytorch/output/rand.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/MusicTransformer-Pytorch/output/rand.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, int(lowest_displayed_pitch), int(highest_displayed_pitch))\n",
        "plt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFMWSDq7ZKM2"
      },
      "source": [
        "### Save to Google Drive (Standard GD connect code) -- DOES NOT WORK WHEN CONNECTED TO VM INSTANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-A3ju-Fz0Eh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DncqBMkFhK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Super_Piano_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}